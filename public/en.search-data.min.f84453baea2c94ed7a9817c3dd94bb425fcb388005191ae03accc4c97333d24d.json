[{"id":0,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhosue/","title":"clickhosue","section":"数据库","content":"clickhouse基础功能介绍\n"},{"id":1,"href":"/docs/java%E5%9F%BA%E7%A1%80/","title":"java基础","section":"Docs","content":"java全栈知识体系: https://pdai.tech/md/java/basic/java-basic-lan-basic.html\n"},{"id":2,"href":"/docs/%E5%85%B6%E4%BB%96/c%E8%AF%AD%E8%A8%80/","title":"其他","section":"其他","content":" SOP: 定义: standard operating procedure , 标准操作过程用来提升效率、提高产出\n参考:https://en.wikipedia.org/wiki/Standard_operating_procedure\nDAU\nPV\nUV\nVV\nWAU\nSLA\nQPS\nTPS\nPIP performance improvement protocol,绩效提升协议\n普适性扩展\nHumble 谦逊\nBFF Backends for Frontends 的简写，为了前端的后端\nWEB\nAPP\nOPEN API\n小程序\n"},{"id":3,"href":"/docs/%E5%88%86%E5%B8%83%E5%BC%8F/raft%E5%8D%8F%E8%AE%AE/","title":"分布式","section":"分布式","content":"+++\nraft 算法是 Multi-Paxos 的一个变种，其简化了 Multi-Paxos 的思想，变得更容易被理解以及工程实现，实际项目中可以优先考虑 Raft 算法\n+++\n\u00151、拜占庭将军\n假设多位拜占庭将军中没有叛军，信使的信息可靠但有可能被暗杀的情况下，将军们如何达成是否要进攻的一致性决定？\n解决方案\n举例如下：假如现在一共有 3 个将军 A，B 和 C，每个将军都有一个随机时间的倒计时器，倒计时一结束，这个将军就把自己当成大将军候选人，然后派信使传递选举投票的信息给将军 B 和 C，如果将军 B 和 C 还没有把自己当作候选人（自己的倒计时还没有结束），并且没有把选举票投给其他人，它们就会把票投给将军 A，信使回到将军 A 时，将军 A 知道自己收到了足够的票数，成为大将军。在有了大将军之后，是否需要进攻就由大将军 A 决定，然后再去派信使通知另外两个将军，自己已经成为了大将军。如果一段时间还没收到将军 B 和 C 的回复（信使可能会被暗杀），那就再重派一个信使，直到收到回复。 2、SOP(共识算法) # 共识算法\n3 leader选举 # raft 使用心跳机制来触发 Leader 的选举。\n如果一台服务器能够收到来自 Leader 或者 Candidate 的有效信息，那么它会一直保持为 Follower 状态，并且刷新自己的 electionElapsed，重新计时。\nLeader 会向所有的 Follower 周期性发送心跳来保证自己的 Leader 地位。如果一个 Follower 在一个周期内没有收到心跳信息，就叫做选举超时，然后它就会认为此时没有可用的 Leader，并且开始进行一次选举以选出一个新的 Leader。\n为了开始新的选举，Follower 会自增自己的 term 号并且转换状态为 Candidate。然后他会向所有节点发起 RequestVoteRPC 请求， Candidate 的状态会持续到以下情况发生：\n赢得选举 其他节点赢得选举 一轮选举结束，无人胜出 赢得选举的条件是：一个 Candidate 在一个任期内收到了来自集群内的多数选票（N/2+1），就可以成为 Leader。\n在 Candidate 等待选票的时候，它可能收到其他节点声明自己是 Leader 的心跳，此时有两种情况：\n该 Leader 的 term 号大于等于自己的 term 号，说明对方已经成为 Leader，则自己回退为 Follower。 该 Leader 的 term 号小于自己的 term 号，那么会拒绝该请求并让该节点更新 term。 由于可能同一时刻出现多个 Candidate，导致没有 Candidate 获得大多数选票，如果没有其他手段来重新分配选票的话，那么可能会无限重复下去。\nraft 使用了随机的选举超时时间来避免上述情况。每一个 Candidate 在发起选举后，都会随机化一个新的枚举超时时间，这种机制使得各个服务器能够分散开来，在大多数情况下只有一个服务器会率先超时；它会在其他服务器超时之前赢得选举\n日志复制 # 一旦选出了 Leader，它就开始接受客户端的请求。每一个客户端的请求都包含一条需要被复制状态机（Replicated State Mechine）执行的命令。\nLeader 收到客户端请求后，会生成一个 entry，包含\u0026lt;index,term,cmd\u0026gt;，再将这个 entry 添加到自己的日志末尾后，向所有的节点广播该 entry，要求其他服务器复制这条 entry。\n如果 Follower 接受该 entry，则会将 entry 添加到自己的日志后面，同时返回给 Leader 同意。\n如果 Leader 收到了多数的成功响应，Leader 会将这个 entry 应用到自己的状态机中，之后可以成为这个 entry 是 committed 的，并且向客户端返回执行结果。\nraft 保证以下两个性质：\n在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们一定有相同的 cmd 在两个日志里，有两个 entry 拥有相同的 index 和 term，那么它们前面的 entry 也一定相同 通过“仅有 Leader 可以生存 entry”来保证第一个性质，第二个性质需要一致性检查来进行保证。\n一般情况下，Leader 和 Follower 的日志保持一致，然后，Leader 的崩溃会导致日志不一样，这样一致性检查会产生失败。Leader 通过强制 Follower 复制自己的日志来处理日志的不一致。这就意味着，在 Follower 上的冲突日志会被领导者的日志覆盖。\n为了使得 Follower 的日志和自己的日志一致，Leader 需要找到 Follower 与它日志一致的地方，然后删除 Follower 在该位置之后的日志，接着把这之后的日志发送给 Follower。\nLeader 给每一个Follower 维护了一个 nextIndex，它表示 Leader 将要发送给该追随者的下一条日志条目的索引。当一个 Leader 开始掌权时，它会将 nextIndex 初始化为它的最新的日志条目索引数+1。如果一个 Follower 的日志和 Leader 的不一致，AppendEntries 一致性检查会在下一次 AppendEntries RPC 时返回失败。在失败之后，Leader 会将 nextIndex 递减然后重试 AppendEntries RPC。最终 nextIndex 会达到一个 Leader 和 Follower 日志一致的地方。这时，AppendEntries 会返回成功，Follower 中冲突的日志条目都被移除了，并且添加所缺少的上了 Leader 的日志条目。一旦 AppendEntries 返回成功，Follower 和 Leader 的日志就一致了，这样的状态会保持到该任期结束。\n参考:\nhttps://javaguide.cn/distributed-system/theorem\u0026algorithm\u0026protocol/raft-algorithm.html#_2-2-%E4%BB%BB%E6%9C%9F\n"},{"id":4,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E7%B4%A2%E5%BC%95/","title":"索引","section":"mysql","content":" 索引覆盖\n索引下推\n当你的查询语句的执行计划里，出现了 Extra 为 Using index condition，那么说明使用了索引下推的优化。\n"},{"id":5,"href":"/docs/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/gmp%E6%A8%A1%E5%9E%8B/","title":"Gmp模型","section":"go语言基础","content":"G的大小: 2-4k\n线程的大小 M?\n1、我们通过 go func () 来创建一个 goroutine；\n2、有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；\n3、G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；\n4、一个 M 调度 G 执行的过程是一个循环机制；\n5、当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P；\n6、当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中\n参考链接: https://learnku.com/articles/41728\n进程和线程:http://staff.ustc.edu.cn/~huangwc/osppt/2.pdf\n视频理解:https://www.bilibili.com/video/BV1hv411x7we?p=16\n"},{"id":6,"href":"/docs/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/slice/","title":"Slice","section":"go语言基础","content":"切片底层储存数组,\n扩容机制\n底层数据会随着扩容二进行扩容,回溯时用到数据要特别注意.\n切片传参\ncopy(copyData,srcData)\nhttps://leetcode.cn/problems/combination-sum-ii/submissions/\n"},{"id":7,"href":"/docs/go%E8%AF%AD%E8%A8%80%E5%9F%BA%E7%A1%80/%E5%8F%8D%E5%B0%84/","title":"反射","section":"go语言基础","content":" 1 反射使用 # 1.1 反射获取数据类型 # 通过relfect.TypeOf() 获取对应的类型,这个方法可以返回类型元数据信息,\nName方法返回类型对应的名字,如果是slice类型或者是指针类型,返回为空字符串 Kind方法对应的数据类型,int、string、struct、func,枚举值reflect.Kind类型 Size: 数据占用内存大小,单位字节 \u0026hellip; type Type interface { ... Name() string // 返回类型对应的名字 PkgPath() string // 类型所在路径 Kind() Kind // 类型元数据的所属类型,int32、float32、string、slice、map、struct、ptr... Elem() Type // 数组、切片、chan、map、指针类型存储的数据信息,其他类型会panic Field(i int) StructField // 返回sturct的某个字段元数据信息 ... } type Foo struct { Name string `tag1:\u0026#34;First Tag\u0026#34; tag2:\u0026#34;Second Tag\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } func main() { testCase := []interface{}{ 1, \u0026#34;1\u0026#34;, []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;}, map[int]int{1: 1, 2: 2}, Foo{ Name: \u0026#34;foo\u0026#34;, Age: 12, }, ioutil.ReadAll, \u0026amp;Foo{}, } for _, v := range testCase { callReflect(v) } } func callReflect(i interface{}) { of := reflect.TypeOf(i) if of.Kind() != reflect.Struct { fmt.Println(\u0026#34;name: \u0026#34;, of.Name(), \u0026#34;kind:\u0026#34;, of.Kind(), \u0026#34;size:\u0026#34;, of.Size()) return } fmt.Println(\u0026#34;name: \u0026#34;, of.Name(), \u0026#34;kind:\u0026#34;, of.Kind(), \u0026#34;size:\u0026#34;, \u0026#34;tag:\u0026#34;, of.Size(), of.Field(0).Tag) } 输出: name: int kind: int size: 8 name: string kind: string size: 16 name: kind: slice size: 24 name: kind: map size: 8 name: Foo kind: struct size: tag0: 24 tag1:\u0026#34;First Tag\u0026#34; tag2:\u0026#34;Second Tag\u0026#34; name: kind: func size: 8 name: kind: ptr size: 8 1.2 反射获取对应的值 # func main() { testCase := []interface{}{1, \u0026#34;1\u0026#34;, []string{\u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;}, map[int]int{1: 1, 2: 2}, Foo{Name: \u0026#34;foo\u0026#34;, Age: 12}, ioutil.ReadAll, \u0026amp;Foo{}} for _, v := range testCase { callReflect(v) } } func callReflect(i interface{}) { of := reflect.ValueOf(i) // reflect.ValueOf获取对应的数据值,先判断数据的Kind,然后在进行取值,否则会panic kind := of.Kind() switch kind { case reflect.Int: fmt.Println(of.Int()) case reflect.String: fmt.Println(of.String()) case reflect.Slice: for i := 0; i \u0026lt; of.Len(); i++ { fmt.Print(\u0026#34;slice :\u0026#34;, of.Index(i).String(), \u0026#34;\\t\u0026#34;) } fmt.Println() case reflect.Map: for _, v := range of.MapKeys() { fmt.Print(\u0026#34;map,key:\u0026#34;, v.Int(), \u0026#34;value:\u0026#34;, of.MapIndex(v).Int(), \u0026#34;\\t\u0026#34;) } fmt.Println() case reflect.Struct: fmt.Printf(\u0026#34;struct ,Name %s,age:%d\\n\u0026#34;, of.Field(0).String(), of.Field(1).Int()) } } 输出: 1 1 slice :1 slice :2 map,key:1value:1 map,key:2value:2 struct ,Name foo,age:12 1.3 反射修改值 # 通过reflect.ValueOf() 中传递指针可以对通过反射修改对应的数据,首先调用Elem方法,然后调用set方法进行修改,reflect的中的各种方法大多数误操作都会导致程序panic,所以在进行操作时\n私有变量的值不能进行修改,可以通过unsafe.Pointer进行修改\ntype Foo struct { Name string `tag1:\u0026#34;First Tag\u0026#34; tag2:\u0026#34;Second Tag\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } func main() { f := Foo{Name: \u0026#34;foo\u0026#34;, Age: 12} callReflect(\u0026amp;f) fmt.Printf(\u0026#34;reflct value:%v\u0026#34;, f) } func callReflect(i interface{}) { if reflect.TypeOf(i).Kind() != reflect.Ptr { // 检测是否为指针,非指针拒绝修改 panic(\u0026#34;not ptr,cannot modify\u0026#34;) } of := reflect.ValueOf(i).Elem() // Elem 取地址实际指向的值 if of.Kind() == reflect.Struct \u0026amp;\u0026amp; of.Type().Name() == \u0026#34;Foo\u0026#34; { // 判断类型 if f := of.Field(1); f.CanSet() { //判断是否可以修改 f.SetInt(100) // 进行修改 } if f := of.Field(0); f.CanSet() { f.SetString(\u0026#34;reflect\u0026#34;) } return } 输出: reflct value:{reflect 100} 1.4 反射make # 可以通过反射创建数据,输入参数relcet.Type类型,输出为reflect.Value类型\nslice通过reflect.MakeSlice 创建,reflect.Append添加对应的元素 map通过内置的reflect.MakeMap创建 function通过reflect.MakeFunc创建 chan创建通过reflect.MakeChan 创建一个新的struct 通过reflect.StructOf函数创建,这种方式比较奇怪,应为新定义的struct 没有对应的名字,如果需要修改对应的struct 实例值,需要通过反射就行修改 2 反射优缺点 # 反射的优点\n通用性，可对类库和框架代码做极大的简化设计 灵活性，运行期动态获取数据的类型 反射的缺点:\n同样因为反射的概念和语法都比较抽象，滥用反射会使得代码难以被其他人读懂无法在编译时检查错误。 作为一种强类型的语言，go 的编译器会在编译阶段检查出类型错误，但是 interface 定义的类型是不明确的，代码在运行时存在 panic 的风险 降低了代码运行的效率，反射变量的类型需要额外的开销, 参考第4节 3 原理走读 # 3.1 类型元数据 # 类型名称、类型大小、对齐边界、是否自定义等，是每个类型元数据都要记录的信息，所以被放到了runtime.type中，作为每个类型元数据的header\nreflect.TypeOf 返回的type接口,对应*reflect.rtype类型, 和runtime._type完全一致\n![image-20220825110648993](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220825110648993.png)\n_type 结构:\ntype _type struct { size uintptr // 类型大小 ptrdata uintptr // size of memory prefix holding all pointers hash uint32 tflag tflag align uint8 // 对齐边界 fieldAlign uint8 kind uint8 // 类型的种类 // function for comparing objects of this type // (ptr to object A, ptr to object B) -\u0026gt; ==? equal func(unsafe.Pointer, unsafe.Pointer) bool // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte str nameOff // 类型名称字符串 ptrToThis typeOff } slice type:\ntype slicetype struct { typ _type // slice 类型 elem *_type // slice里的元数据类型 } map type:\ntype maptype struct { typ _type key *_type // key类型 elem *_type // value类型 bucket *_type // internal type representing a hash bucket // function for hashing keys (ptr to key, seed) -\u0026gt; hash hasher func(unsafe.Pointer, uintptr) uintptr keysize uint8 // size of key slot elemsize uint8 // size of elem slot bucketsize uint16 // size of bucket flags uint32 } stuct type:\ntype structtype struct { typ _type // 类型 pkgPath name // 包路径 fields []structfield // 字段 } type structfield struct { name name typ *_type offsetAnon uintptr } interface type:\ntype interfacetype struct { typ _type pkgpath name mhdr []imethod } 3.2 接口 # 接口类型的数据在运行中将会转变成以下两种类型\n3.2.1 空接口 # runtime.eface\ntype eface struct { _type *_type //动态类型 data unsafe.Pointer // 接口动态值 } 3.2.2 非空接口 # runtime.iface\n// iface 结构 type iface struct { tab *itab // itab结构体 data unsafe.Pointer //动态值 } // itab 结构体 type itab struct { inter *interfacetype //接口类型,定义接口实现的方法 _type *_type // 动态类型 hash uint32 // copy of _type.hash. Used for type switches. _ [4]byte fun [1]uintptr // 动态类型实现的接口方法拷贝,系统会维持一份itab缓存,fun[0]==0 表示未实现对应的接口, } 类型别名与类型重定义\ntype rune=int32 同一种类型元数据\ntype type2 []slice 不同的类型元数据\ntype any = interface{} // go version1.18\n3.3 类型断言 # int、string、 slice、map 、空接口、非空接口\n空接口.(具体类型)\n![image-20220825112856067](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220825112856067.png)\n只需要根据空接口的type 和被断言类型进行一次比较即可\n非空接口.(具体类型)\n![image-20220825113126766](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220825113126766.png)\n非空接口运行时结构为itab,和data类型,需要判断接口的动态类型*os.File是否实现了io.ReadWriter接口类型,只需要遍历动态类型实现的方法,如果对应的方法实现了io.ReadWriter接口,则类型断言成功.\n接口类型和对应的动态类型确定下来,对应的itab接口就不会在进行变更,所以go内部会维持一个itab缓存,用于加快比较操作,用接口的hash^动态类型的hash,如果在itab缓存中则代表动态类型实现了接口\ntype itabTableType struct { size uintptr // length of entries array. Always a power of 2. count uintptr // current number of filled entries. entries [itabInitSize]*itab // really [size] large } func (t *itabTableType) find(inter *interfacetype, typ *_type) *itab { .... } 空接口.(非空接口)\n![image-20220820212352618](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220820212352618.png)\n比较空接口的动态类型是否实现非空接口的方法 非空接口和空接口的动态类型是否在itab缓存中接口 非空接口.(非空接口)\n![image-20220820213907033](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220820213907033.png)\n比较动态类型是否实现非空接口的方法 被断言非空接口和动态类型是否在itab缓存中接口 3.4 接口与反射 # 反射可以将“接口类型变量”转换为“反射类型对象”\n反射可以将“反射类型对象”转换为“接口类型变量”\n如果要修改“反射类型对象”，其值必须是“可写的”（settable） https://go.dev/blog/laws-of-reflection\nfunc main() { testInt := 1 of := reflect.ValueOf(testInt) // 接口类型值转换为反射类型的值, law-1 reflectInt := of.Interface() // 反射类型的值转换为接口类型的值 law-2 //of.SetInt(19) //panic law-3 reflect.ValueOf(\u0026amp;testInt).Elem().SetInt(12) fmt.Println(reflectInt, testInt) } ![image-20220820112359414](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20220820112359414.png)\n​\treflect中的rtype结构和runtime._type接口保持一致,runtime包中的内容不允许访问,所以才有了reflect包\n4 反射性能 # type Foo struct { Name string `tag1:\u0026#34;First Tag\u0026#34; json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } func BenchmarkReflectUpdate(b *testing.B) { f := Foo{ Name: \u0026#34;origin\u0026#34;, Age: 1, } for i := 0; i \u0026lt; b.N; i++ { //ReflectUpdate(\u0026amp;f) f.Name = \u0026#34;origin set\u0026#34; f.Age = i } } // ReflectUpdate 反射修改 f 值 func ReflectUpdate(f interface{}) { v := reflect.ValueOf(f) if v.Kind() != reflect.Ptr \u0026amp;\u0026amp; v.Elem().Type().Name() != \u0026#34;Foo\u0026#34; { panic(\u0026#34;not match type\u0026#34;) } ve := v.Elem() //ve.Field(0).SetString(\u0026#34;reflect modify\u0026#34;) //ve.Field(1).SetInt(100) ve.FieldByName(\u0026#34;Name\u0026#34;).SetString(\u0026#34;fieldByName modify\u0026#34;) ve.FieldByName(\u0026#34;Age\u0026#34;).SetInt(999) } 测试结果: 直接赋值: goos: darwin goarch: amd64 BenchmarkReflectUpdate BenchmarkReflectUpdate-12 1000000000\t0.291 ns/op field反射: goos: darwin goarch: amd64 BenchmarkReflectUpdate BenchmarkReflectUpdate-12 55756632\t18.5 ns/op fieldByName反射: goos: darwin goarch: amd64 BenchmarkReflectUpdate BenchmarkReflectUpdate-12 8810466\t123 ns/op 直接赋值~=63*Field反射~=422*FieldByName反射修改 5 反射应用 # 官方包：\nfmt系列\nfmt.Printf(\u0026#34;%T\u0026#34;,5) 对应的代码: switch verb { case \u0026#39;T\u0026#39;: p.fmt.fmtS(reflect.TypeOf(arg).String()) return case \u0026#39;p\u0026#39;: p.fmtPointer(reflect.ValueOf(arg), \u0026#39;p\u0026#39;) return } reflect.DeepEqual\n比较类型,类型不同返回false, 递归比较值 func TestDeepReflect(t *testing.T) { var a int32 = 1 var b rune = 1 fmt.Println(reflect.DeepEqual(a, b)) } 结果: === RUN TestDeepReflect true --- PASS: TestDeepReflect (0.00s) PASS json 对象序列化和反序列化\nfunc Marshal(v interface{})([]byte, error) //接口interface{}类型,返回字节切片 func Unmarshal(data []byte, v interface{}) error // 如果为字节切片, interface类型4、... 第三方包\nproto reflect xorm: go提供的关系对象模型操作库,运用反射 switch beanKind { case reflect.Struct: 下·下· fields, err := rows.Columns() if err != nil { // WARN: Alougth rows return true, but get fields failed return true, err } scanResults, err := session.row2Slice(rows, fields, bean) if err != nil { return false, err } // close it before covert data rows.Close() dataStruct := rValue(bean) _, err = session.slice2Bean(scanResults, fields, bean, \u0026amp;dataStruct, table) if err != nil { return true, err } return true, session.executeProcessors() "},{"id":8,"href":"/docs/java%E5%9F%BA%E7%A1%80/juc/","title":"Juc","section":"java基础","content":"juc并发编程\n主要掌握以下几个类的使用方法:\nCAS\npublic class Cas { public static void main(String[] args) { // 无法控制并发 AtomicInteger ai = new AtomicInteger(1); System.out.println(ai.compareAndSet(0, 2)); System.out.println(ai.compareAndSet(1, 2)); // Unsafe unsafe = Unsafe.getUnsafe(); } } ABA问题,, 1\u0026mdash; \u0026gt;2 \u0026mdash;\u0026mdash;\u0026gt;1 发生了改变, 但外部并不清楚这种改变\npublic static void main(String[] args) { // 无法控制并发 AtomicInteger ai = new AtomicInteger(1); System.out.println(ai.compareAndSet(0, 2)); System.out.println(ai.compareAndSet(1, 2)); // Unsafe unsafe = Unsafe.getUnsafe(); AtomicStampedReference atomicStampedReference = new AtomicStampedReference(2,3); System.out.println(atomicStampedReference.compareAndSet(2, 2, 3, 1)); System.out.println(atomicStampedReference.compareAndSet(2, 3, 3, 1)); } Atomic 类\n​\tcountdownlatch\npublic static void main(String[] args) throws InterruptedException { CountDownLatch countDownLatch = new CountDownLatch(2); new Thread(()-\u0026gt;{ System.out.println(1); countDownLatch.countDown(); }).start(); new Thread(()-\u0026gt;{ System.out.println(2); countDownLatch.countDown(); }).start(); // 同步等待2个线程同步完成 countDownLatch.await(); } 使用场景:同步等待\nCyclicBarrier # public class CyclicBarrierDemo { private final static int gradeNum = 6; private static CyclicBarrier barrier = new CyclicBarrier(6,()-\u0026gt;{ System.out.println(\u0026#34;====================\u0026#34;); }); public static void main(String[] args) throws Exception { ExecutorService exec = Executors.newScheduledThreadPool(gradeNum); System.out.println(\u0026#34;通知、通知，请准备的年级先出发.....\u0026#34;); for (int i = 0; i \u0026lt; gradeNum; i++) { TimeUnit.SECONDS.sleep(1); int gradeName = i + 1; exec.submit(() -\u0026gt; { try { wait(gradeName); } catch (Exception e) { } }); } // exec.shutdown(); for (int i = 0; i \u0026lt; gradeNum; i++) { TimeUnit.SECONDS.sleep(1); int gradeName = i + 1; exec.submit(() -\u0026gt; { try { wait(gradeName); } catch (Exception e) { } }); } // ThreadPool 线程池需要关闭，否则整个jvm进程不会退出 exec.shutdown(); } private static void wait(int gradeName) throws Exception { TimeUnit.SECONDS.sleep(1); System.out.println(gradeName + \u0026#34;年级所有同学来到了出口......\u0026#34;); barrier.await(); } } 可循环同步节点\nSemaphore # ​\t信号量,抢占资源使用\n重要方法 acquire 、release\n​\npublic class SeamphoreDemo { public static void main(String[] args) throws InterruptedException { Semaphore seamphore = new Semaphore(0); boolean b = seamphore.tryAcquire(); System.out.printf(\u0026#34;acquire:%b\\n\u0026#34;,b); seamphore.release(); b = seamphore.tryAcquire(); System.out.printf(\u0026#34;acquire:%b\\n\u0026#34;,b); } } CountDownLatch和CyclicBarrier都用于实现多线程之间的相互等待，但二者的关注点不同。CountDownLatch主要用于主线程等待其他子线程任务均执行完毕后再执行接下来的业务逻辑单元，而CyclicBarrier主要用于一组线程互相等待大家都达到某个状态后，再同时执行接下来的业务逻辑单元。此外，CountDownLatch是不可以重用的，而CyclicBarrier`是可以重用的\nSemaphore和Java中的锁功能类似，主要用于控制资源的并发访问**\n锁 # synchronized # ReentrantLock\nReentrantReadWriteLock\n参考文档: https://segmentfault.com/a/1190000037600050\n"},{"id":9,"href":"/docs/java%E5%9F%BA%E7%A1%80/jvm/","title":"Jvm","section":"java基础","content":" 类加载机制 # GC策略 # 对象优先分配在eden区\n大对象直接分配在老年代\n长期存活的对象分配在老年代\n进入survior 区 或者survior 每经历一次minor gc 年龄+1 累计年龄的对象数超过50% 默认年龄阈值15, cms默认6 取累计年龄和默认年龄的最小值 GC分类 # partial GC:\nYoung GC (Minor GC), 只收集young gen代的GC Old GC ,只收集Old gen的GC MixedGC 手机young gen和old gen 的GC, 只有G1支持这种模式 Full GC:\n收集整个堆的数据,young gen、old gen、perm gen major gc 和full gc等价, 概念混乱,也有major gc和old gc等价的说法,\n引用类型 # 强引用(Strong Reference)\n弱引用(Weak Reference)\n不管当前内存空间足够与否，都会回收它的内存,比Soft Reference 拥有更短的生命周期\n软引用(Soft Reference)\n内存空间不足时,进行回收\n虚引用(Phantom Reference)\n虚引用并不会决定对象的生命周期。如果一个对象仅持有虚引用，那么它就和没有任何引用一样，在任何时候都可能被垃圾回收\n常量池 # 字符串常量池位于堆中\n运行时常量池位于方法区(元空间)\n如何判断一个类是无用的类 # 对象无引用 class 对象无引用, 无法通过反射生成对象实例 classloader 无引用 垃圾回收算法 # 标记清除\n标记整理\n老年代采用的回收算法\n标记复制\n新生代常采用算法, 分配担保\n分代收集\n垃圾收集器 # serial 收集器 ​\tstop the world\nParNew收集器 ​\tParNew 收集器其实就是 Serial 收集器的多线程版本，除了使用多线程进行垃圾收集外，其余行为（控制参数、收集算法、回收策略等等）和 Serial 收集器完全一样。\n新生代采用标记-复制算法， 老年代采用标记-整理算法 Parallel Scanvage 使用标记-复制算法的多线程收集 提供系统的吞吐量, 提高系统cpu使用率 JDK1.8 默认使用的是 Parallel Scavenge + Parallel Old 新生代采用标记-复制算法，老年代采用标记-整理算法 serial old收集器 serial收集器的老年代版本 一种用途是在 JDK1.5 以及以前的版本中与 Parallel Scavenge 收集器搭配使用 另一种用途是作为 CMS 收集器的后备方案 parallel old\nparallel scanvatge的老年代版本 标记整理 和paralle scanvage 搭配使用 ,ps/po cms收集器 concurrent mark swap 并发标记清除\n无法清除浮动垃圾\n标记清除算法,会产生大量空间碎片\n过程\n和redis 增量同步方式相同\n初始标记\n并发标记\n重新标记\n并发清楚\nG1收集器 G1 从整体来看是基于“标记-整理”算法实现的收集器；从局部上来看是基于“标记-复制”算法实现的 过程 初始标记 并发标记 最终标记 筛选回收 ZGC ​\t标记-复制的垃圾收集器\n"},{"id":10,"href":"/docs/java%E5%9F%BA%E7%A1%80/lambda/","title":"Lambda","section":"java基础","content":" Optional # Optional用法:\n无法判断被调用传递过来的list 是否为空, 可以省略if null的判断条件\nList\u0026lt;String\u0026gt; carsFiltered = Optional.ofNullable(cars) .orElseGet(Collections::emptyList) .stream() .filter(Objects::nonNull) //filtering car object that are null .map(Car::getName) //now it\u0026#39;s a stream of Strings .filter(Objects::nonNull) //filtering null in Strings .filter(name -\u0026gt; name.startsWith(\u0026#34;M\u0026#34;)) .collect(Collectors.toList()); //back to List of Strings "},{"id":11,"href":"/docs/java%E5%9F%BA%E7%A1%80/skiplist/","title":"Skiplist","section":"java基础","content":"跳表\n"},{"id":12,"href":"/docs/java%E5%9F%BA%E7%A1%80/volatile/","title":"Volatile","section":"java基础","content":"volatile用来保证变量可见性\n"},{"id":13,"href":"/docs/java%E5%9F%BA%E7%A1%80/%E5%9F%BA%E6%9C%AC%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","title":"基本数据类型","section":"java基础","content":" Integer # Integer == int 整型会自动装箱与拆箱,\nInteger m = 323; int n = 323; System.out.println(m == n); // true Interger == Integer 比较的时对象, -128-127 连接的是同一对象,其他的指向不同对象\nInteger m = 323; Integer n = 323; System.out.println(m == n); // false String # 不可以变对象final\nString 不可变性天生具备线程安全，可以在多个线程中安全地使用。\n如果一个 String 对象已经被创建过了，那么就会从 String Pool 中取得引用。只有 String 是不可变的，才可能使用 String Pool。\nJDK版本 是否有永久代，字符串常量池放在哪里？ 方法区逻辑上规范，由哪些实际的部分实现的？ jdk1.6及之前 有永久代，运行时常量池（包括字符串常量池），静态变量存放在永久代上 这个时期方法区在HotSpot中是由永久代来实现的，以至于这个时期说方法区就是指永久代 jdk1.7 有永久代，但已经逐步“去永久代”，字符串常量池、静态变量移除，保存在堆中； 这个时期方法区在HotSpot中由永久代（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 jdk1.8及之后 取消永久代，类型信息、字段、方法、常量保存在本地内存的元空间，但字符串常量池、静态变量仍在堆中 这个时期方法区在HotSpot中由本地内存的元空间（类型信息、字段、方法、常量）和堆（字符串常量池、静态变量）共同实现 可变字符串:\nStringBuffer\n线程不安全\nStringBuilder\n线程安全的，内部使用 synchronized 进行同步\nthrowable # throwable 可以用来表示任何可以作为异常抛出的类，分为两种: Error 和 Exception。其中 Error 用来表示 JVM 无法处理的错误，Exception 分为两种:\n受检异常 : 需要用 try\u0026hellip;catch\u0026hellip; 语句捕获并进行处理，并且可以从异常中恢复； 非受检异常 : 是程序运行时错误，例如除 0 会引发 Arithmetic Exception，此时程序崩溃并且无法恢复。 "},{"id":14,"href":"/docs/java%E5%9F%BA%E7%A1%80/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","title":"线程池","section":"java基础","content":"TODO\n线程状态\n新建: new\n就绪: 等待cpu调度 (start方法), Thread.yield() 会让线程从运行状态转换为就绪状态\n运行 : running状态 ,Thread.sleep()不会释放线程,只是会释放cpu占用\n阻塞: 等待资源\n等待 : monitor.wait\n终止: stop\n"},{"id":15,"href":"/docs/java%E5%9F%BA%E7%A1%80/%E9%9B%86%E5%90%88/","title":"集合","section":"java基础","content":" List # 默认大小为10\n扩容规则\n每次扩容 1.5倍 扩容后任然不够大小,直接使用最小的数据大小 大于最大容量,取最大容量 扩展点\ngo slice扩容规则\n小于1024 ,扩容两倍 double容量不能容纳,直接使用预估的容量 大于1024 ,扩容1.25倍 "},{"id":16,"href":"/docs/linux/","title":"Linux","section":"Docs","content":"title: \u0026#34;java基础\u0026#34; bookCollapseSection: false "},{"id":17,"href":"/docs/linux/nvim/","title":"Nvim","section":"Linux","content":" 文件查找: # 查找空间下文件 ff\n查到打开的文件 fb\n新建termimal # 上线窗口 - h\n左右窗口 -vh :\n"},{"id":18,"href":"/docs/linux/%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","title":"常用命令","section":"Linux","content":" dmesg|egrep -i -B100 \u0026lsquo;killed process\u0026rsquo;\nlsof\nnetstat\ntcpdump\n​\n"},{"id":19,"href":"/docs/%E5%85%B6%E4%BB%96/%E5%85%B6%E4%BB%96/","title":"其他","section":"其他","content":" java 锁 # 自旋锁 实现cpu空转 会存在超时的情况\nReentrantLock # 可重入锁: 巧用condition\n用这个await 、notifyAll 可以实现线程通信,但是出现超时情况\nSemaphore # 交替打印:\nclass FooBar { private int n; Semaphore fooS = new Semaphore(1); Semaphore barS = new Semaphore(0); public FooBar(int n) { this.n = n; } public void foo(Runnable printFoo) throws InterruptedException { for (int i = 0; i \u0026lt; n; i++) { fooS.acquire(); printFoo.run(); barS.release(); } } public void bar(Runnable printBar) throws InterruptedException { for (int i = 0; i \u0026lt; n; i++) { barS.acquire(); printBar.run(); fooS.release(); } } } volatile # volatile实现比较轻量化\nCyclicBarrier # class FizzBuzz { private int n; CyclicBarrier barrier = new CyclicBarrier(4); public FizzBuzz(int n) { this.n = n; } // printFizz.run() outputs \u0026#34;fizz\u0026#34;. public void fizz(Runnable printFizz) throws InterruptedException { for(int i=1;i\u0026lt;=n;i++){ if(i%3==0 \u0026amp;\u0026amp; i%5!=0){ printFizz.run(); } try{ barrier.await(); // await 到点循环 }catch(Exception e){ } } } // printBuzz.run() outputs \u0026#34;buzz\u0026#34;. public void buzz(Runnable printBuzz) throws InterruptedException { for(int i=1;i\u0026lt;=n;i++){ if(i%5==0\u0026amp;\u0026amp;i%3!=0){ printBuzz.run(); } try{ barrier.await(); }catch(Exception e){ } } } // printFizzBuzz.run() outputs \u0026#34;fizzbuzz\u0026#34;. public void fizzbuzz(Runnable printFizzBuzz) throws InterruptedException { for(int i=1;i\u0026lt;=n;i++){ if(i%15==0){ printFizzBuzz.run(); } try{ barrier.await(); }catch(Exception e){ } } } // printNumber.accept(x) outputs \u0026#34;x\u0026#34;, where x is an integer. public void number(IntConsumer printNumber) throws InterruptedException { for(int i=1;i\u0026lt;=n;i++){ if(i%3!=0\u0026amp;\u0026amp;i%5!=0){ printNumber.accept(i); } try{ barrier.await(); }catch(Exception e){ } } } } kafka # offset管理 # 每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，老版本是写入zk，但是那样高并发请求zk是不合理的架构设计，zk是做分布式系统的协调的，轻量级的元数据存储，不能负责高并发读写，作为数据存储。 现在新的版本提交offset发送给kafka内部topic：__consumer_offsets，提交过去的时候， key是group.id+topic+分区号，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact(合并)，也就是每个group.id+topic+分区号就保留最新数据。 __consumer_offsets可能会接收高并发的请求，所以默认分区50个(leader partitiron -\u0026gt; 50 kafka)，这样如果你的kafka部署了一个大的集群，比如有50台机器，就可以用50台机器来抗offset提交的请求压力. 时间轮 # ​\t循环数组 + 链表\n​\t使用地方:\nleader向follow发送数据 ,维护时间轮 ,控制超时 follow 向 leader 拉取数据的时候 ,如果拉去的数据为空, 维护时间轮, 过段时间在拉取 io模型 # 基于nio io多路复用\n多个selector监听机制 ? 读请求维护一个队列 ? 高性能写 # ​\t基于mmap , 顺序写\n高性能读 # ​\t使用零拷贝技术 , 避免无用的内存拷贝\n​\t零copy\n零拷贝技术实现的方式通常有 2 种：\nmmap + write sendfile kafka调用java的transfer 接口,底层使用的是sendfile技术,pagecache(通过预读的方式)进一步提升零拷贝的性能,\n直接io: 跳过内核cache,用户cache和磁盘数据进行交互\ncontroller作用 # ​\t维护集群元数据信息, 分区选主 ,\nrebalance # ​\tcoordinator 每个consumer group都会选择一个broker作为自己的coordinator，他是负责监控这个消费组里的各个消费者的心跳，以及判断是否宕机，然后开启rebalance的.\n​\t如何选择coordinator机器 首先对groupId进行hash（数字），接着对__consumer_offsets的分区数量取模，默认是50，_consumer_offsets的分区数可以通过offsets.topic.num.partitions来设置，找到分区以后，这个分区所在的broker机器就是coordinator机器。比如说：groupId，“myconsumer_group” -\u0026gt; hash值（数字）-\u0026gt; 对50取模 -\u0026gt; 8 __consumer_offsets 这个主题的8号分区在哪台broker上面，那一台就是coordinator 就知道这个consumer group下的所有的消费者提交offset的时候是往哪个分区去提交offset\n消费策略 # range 按分区数量划分, round-robin 轮训 sticky (range + sticky) 集群规划 # ​\t考虑并发、内存\n​\t机械硬盘\n问题 # Kafka存储在硬盘上的消息格式是什么？\n一般的协议数据格式 : 版本号、消息长度、校验码 \u0026mdash; 具体消息\nKafka高效文件存储设计特点：\n一个partiton 对应一个文件, 分多段,每段大小固定 (.log、.index) , 方便滚动删除 , 对.log文件进行索引, 并全部映射到内存, 通过二分查找index, 快速定位文件位置\ntopic的分区分配到broker 上由controller节点控制, 随机落在一个接点上 ,轮询分配\n数据存储在logs.dir、log.dirs上 ,分区目录最少的有限分配\nGO # Slice底层实现 # Map 底层实现 # 接口 # GMP # 管道 # ​\tchannel 底层实现原理 :\n协程 # ​\t和线程、线程对比\nhttp # 各版本区别 # 1.0 都需要进行一次tcp连接（即3次握手4次挥手），使得网络的利用率非常低,HTTP 1.0 规定在前一个请求响应到达之后下一个请求才能发送，如果前一个阻塞，后面的请求也给阻塞的 1.1 基于长链接(使用keep-alive参数保证链接不断),默认保持长连接，数据传输完成保持tcp连接不断开,继续用这个通道传输数据,管线化保证发送批量数据 、但是接收端还是得一个个进行处理 2.0 头部压缩 , 二进制编码, 多路复用： 在共享TCP链接的基础上同时发送请求和响应 3.0 基于udp传输,解决tcp 对头阻塞问题 , 基于quic协议进行 长链接 # 短链接 # 长轮询 # ​\t客户端发送一个请求，服务器保持连接打开，直到有新数据或超时。\n短轮询 # ​\t客户端频繁发送请求，服务器及时响应，不管是否有新数据\n配置中心长轮询 # Spring Cloud Config使用长轮询（Long Polling）机制来实现实时获取配置更新的功能。这意味着客户端向配置服务器发送请求，并保持连接打开，直到有新的配置更新或超时发生。\n当客户端向Spring Cloud Config服务器发送配置获取请求时，服务器会在配置更新时立即返回响应，并传递最新的配置信息给客户端。如果没有新的配置更新，服务器会将连接保持一段时间，等待配置的变更事件发生。如果超时时间到达而没有新的配置变更，则服务器会发送一个特殊的响应，指示客户端重新发送配置获取请求。\n通过使用长轮询，Spring Cloud Config可以实现实时的配置更新推送。相对于短轮询，长轮询能够减少无效的请求发送频率，降低了服务器和网络的负载，同时提供了更好的实时性和有效性。\n因此，Spring Cloud Config采用长轮询作为默认的配置获取机制，以实现实时的配置更新推送，提供更好的用户体验和性能。\nhydrix 断路器 # 故障大于50% ,开启状态, 5秒后, 处于半开状态 ,释放一部分流量 , 如果还是失败继续处于开启状态\nvolatile # 请谈谈volatile有什么特点，为什么它能保证变量对所有线程的可见性？\nvolatile 能保证变量对所有线程的可见性的原理是基于 CPU 缓存一致性协议。在多核处理器中，每个 CPU 都有自己的缓存，这些缓存中存储了主存中的部分数据副本。当一个线程修改了某个变量的值时，它会将修改后的值写回到主存中，并通知其他 CPU 缓存该变量的值已经发生了改变。当其他线程访问该变量时，它们会从主存中读取最新的值，而不是从自己的缓存中读取旧的值\nThreadLocal # 使用注意事项:\n需要考虑 内存泄漏问题 , 使用完及时的remove, ThreadLocal惰性删除 ,本身就会删除 线程池问题 , 会有些垃圾数据 ,注意使用场景 redis # 缓存穿透 : 没有的key 穿透\n缓存击穿: 热key过期\n缓存雪崩: 同一时间点, 大面积key过期\n网络模型 # 七层模型 # ​\t物理层、数据链路层、网络层、传输层、会话层、表示层、应用层\n四层模型 # ​\t数据链路层、网络层、传输层、应用层\nARP # ​\taddress resolution protocol, 地址解析协议 ,解析ip和mac地址映射关系\nNAT # ​\tnet address translation , nat地址转换 , 转换ip地址为公网地址\n四次握手 # ![image-20230706144230359](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20230706144230359.png)\n问题 # 如果已经建立了连接，但客户端出现了故障怎么办？ ​\t服务端维持计时器, 每隔一段时间重试,超过一定次数,直接断开连接\n如果第二次挥手时服务器的ACK没有送达客户端，会怎样？\n客户端没有收到ACK确认，会重新发送FIN请求。\n客户端TIME_WAIT状态的意义是什么？\n第四次挥手时，客户端发送给服务器的ACK有可能丢失，TIME_WAIT状态就是用来重发可能丢失的ACK报文。如果Server没有收到ACK，就会重发FIN.\n缓存机制 # 强制缓存, 通过返回请求头的,cache-control, expire字段进行确认 协商缓存, 通过返回的etag,last-modify的返回头进行确认,下次访问的时候(请求头If-Modified-Since,If-None-Match )带上对应etag和最后修改的信息, 服务进行判断,304 HTTPS工作原理 # 一、首先HTTP请求服务端生成证书，客户端对证书的有效期、合法性、域名是否与请求的域名一致、证书的公钥（RSA加密）等进行校验；\n二、客户端生成会话密钥：客户端使用服务器的公钥（从证书中获取）来加密生成一个会话密钥，该密钥将用于双方进行对称加密通信。这样客户端可以确保只有持有服务器私钥的服务器能够解密会话密钥。\n三、握手阶段：客户端将会话密钥加密并发送给服务器。服务器使用私钥解密会话密钥，然后双方就可以使用该会话密钥进行加密和解密通信。\n四、客户端和服务器之间的后续通信和数据传输都是使用会话密钥进行加密和解密的，确保数据的机密性和完整性。\n网络模型(reactor) # 单线程reator、单线程 # 单线程reactor、多线程 # 多线程reactor 、单线程,不常用 # 多线程reator、多线程 # ouath 协议工作流程 # 注册应用程序：客户端向授权服务器注册，并获得客户端ID和客户端密钥。 请求授权：客户端跳转到授权服务器，并请求访问用户受保护资源的授权。请求中包含客户端ID、请求访问的范围和重定向URL等信息。 用户授权：用户在授权服务器上登录，并选择是否授权客户端访问其受保护资源。 授权颁发：授权服务器向客户端颁发授权令牌（Access Token）。授权令牌将用于后续的资源请求。 访问受保护资源：客户端将授权令牌附加到资源请求中，并发送给资源服务器。 验证授权：资源服务器验证授权令牌的有效性，并根据用户的授权范围来限制访问。 提供受保护资源：如果授权有效，则资源服务器提供所请求的受保护资源给客户端。 # springcloud组件 # Spring Cloud Eureka： # ​\t服务注册与发现\nEureka的自我保护机制: 默认情况下，如果Eureka Service在一定时间内没有接收到某个微服务的心跳，Eureka Service会进入自我保护模式，在该模式下Eureka Service会保护服务注册表中的信息，不在删除注册表中的数据，当网络故障恢复后，Eureka Servic节点会自动退出自我保护模式\neureka 和 zookeeper区别? ​\t1.ZooKeeper中的节点服务挂了就要选举在选举期间注册服务瘫痪,虽然服务最终会恢复,但是选举期间不可用的，选举就是改微服务做了集群，必须有一台主其他的都是从\nEureka各个节点是平等关系,服务器挂了没关系，只要有一台Eureka就可以保证服务可用，数据都是最新的。如果查询到的数据并不是最新的，就是因为Eureka的自我保护模式导致的 ZooKeeper保证的是CP，Eureka保证的是AP Spring Cloud Zuul：服务网关\nSpring Cloud Ribbon：客户端负载均衡\nSpring Cloud Feign：声明性的Web服务客户端\nSpring Cloud Hystrix：断路器 # 服务降级：当客户端请求服务器端的时候，防止客户端一直等待，不会处理业务逻辑代码，直接返回一个友好的提示给客户端。实战: Hystrix实现服务降级的功能是通过重写HystrixCommand中的getFallback()方法，当Hystrix的run方法或construct执行发生错误时转而执行getFallback()方法。\n服务熔断是在服务降级的基础上更直接的一种保护方式，当在一个统计时间范围内的请求失败数量达到设定值（requestVolumeThreshold）或当前的请求错误率达到设定的错误率阈值（errorThresholdPercentage）时开启断路，之后的请求直接走fallback方法，在设定时间（sleepWindowInMilliseconds）后尝试恢复。\n服务隔离就是Hystrix为隔离的服务开启一个独立的线程池，这样在高并发的情况下不会影响其他服务。服务隔离有线程池和信号量两种实现方式，一般使用线程池方式。\nSpring Cloud Config：分布式统一配置管理\n限流器: guava ratelimit 、resilience4j、 sentinl限流\nelasticsearch # 分片规划 # ​\t每个分片容量20G-50G左右 ,\n​\t账号库12亿数据 ,线上28个节点, 3T数据,76个分片,\nRedis # Redis 集群, 线上分片24个,4GB ,1个副本, 规划容量100G\nhomo redis # 16个分片共 32g ,1副本,规划容量80G\nclickhouse # 线上40个节点 ,128G内存,96c, 总容量500T, 已使用400T,\ndb # 10个数据库, 然后分表,每个库60张表,\n算法 # java 常用函数\nnew ArrayList(); // 构造函数里面直接加数组\njvm # 常用工具\njps 查看进程 jinfo 运行环境信息,classpath、javasystem 信息 jstat 监控各种运行状态 jstack 线程运行情况 (死锁) jmap 查看物理内存使用情况 GC:\nminor gc 新生代\nmajor gc 老年代\nfullgc system.gc 、方区空间不足\nHotSpot虚拟机中，Eden区和Survivor区的默认比例为8:1:1，即-XX:SurvivorRatio=8， 其中Survivor分为From Survivor和ToSurvivor，因此Eden此时占新生代空间的80%\n内存泄漏 # 数据无法回收 ,ThreadLocal\n内存溢出 # 分配数据时,内存不够使用\n问题排查 # jps 查看java端口\ntop -H -p {进程id} 查看进程对应的线程使用情况\njstack -l {pid} |grep {printf \u0026ldquo;0x%x\u0026rdquo; [线程id]}\nmysql # 执行过程 # 连接器、分析器、优化器、执行器\n存储引擎\n查询缓存 # 8.0之后去除, 基于表的查询缓存, 表有更新,整个缓存全部删除\njava # 动态加载类框架 # reflect aop动态代理 Java Instrumentation API 增强字节码 , 动态修改、添加、删除模块 GO # 原文链接: https://juejin.cn/post/7226153290051141692\nslice # 数组、len、cap 结构\n扩容2倍, ,cap\u0026gt;1024扩容 1.25倍\njava arraylist 扩容是1.5倍, 扩容之后任不够使用,扩容至所需的容量\nMap: # 底层基于 hmap 实现 ,hamp是一个bucket数组结构, 数组里面的每一个bmap是一个bmap结构,每个桶中保存了8个kv对，如果8个满了，又来了一个key落在了这个桶里，会使用overflow连接下一个桶(溢出桶)\n扩容: 扩容条件\n1、负载因\u0026gt; 6.5 , count/bucket数组\u0026gt; 6.5\n2、溢出桶过多, 当B\u0026lt; 15时 ,溢出桶 \u0026gt; 2^B\nB\u0026gt;15时, 溢出桶\u0026gt; 2^15\n扩容方式:\n等量扩容: (缩容)\n2倍扩容\nrehash # 将新数组的容量设置为旧数组的两倍或一半，并且将哈希表的增量计数器加一。\n在对哈希表进行操作时，如果发现增量计数器的值达到了一个阈值，就会开始进行增量式 rehash 操作，将一部分元素从旧数组中复制到新数组中，并且重新计算这些元素的哈希值。\n在完成一次增量式 rehash 操作后，会将哈希表的增量计数器清零。\nGMP模型: # Spring 为什么需要三级缓存解决循环依赖问题 # 实例化和属性设置 分开 , 会涉及到一些代理对象的使用 , 这些是放在第三级缓存里的 , 如果只有两级缓存, 没办法 区分 bean 对象处理属性设置还是bean 代理\nspringboot启动流程 # SpringBootApplication 注解 ,包含 componetscan注解,启动时,会自动拉取jar下的metainfo/spring.factory文件中定义的bean信息, 做好自动装配 , @SpringBootConfiguration注解\nexplain语句 # type :ALL-\u0026gt;const(主键或者唯一索引)-\u0026gt; eq_ref(主键或者唯一索引)-\u0026gt;ref(普通索引)\nkeys : 实际走的索引\npossible_keys : 可能用到的索引\n三级缓存 # 三级缓存存在的原因主要原因有两个，一是因为AOP，二是循环依赖。如果没有Spring AOP和循环依赖，那么就不需要使用三级缓存\n一级缓存存放完全实力化的bean 二级缓存存放还没有完全实例化的bean 三级缓存存放需要aop功能等代理生成的bean 如果没有AOP的话确实可以两级缓存就可以解决循环依赖的问题，如果加上AOP，两级缓存是无法解决的，不可能每次执行singleFactory.getObject()方法都给我产生一个新的代理对象，所以还要借助另外一个缓存来保存产生的代理对象\ngc # GC 耗时增大、线程 Block 增多、慢查询增多、CPU 负载高等四个表象，如何判断哪个是根因\n入侵检测、ddos 、业务安全、 数据安全、 网络安全\n​\n"},{"id":20,"href":"/docs/%E5%85%B6%E4%BB%96/%E6%9E%B6%E6%9E%84%E5%9F%BA%E7%A1%80/","title":"架构基础","section":"其他","content":" 文件存储 # nfs: network file system , 提供文件挂在功能 ,NFS挂在本地,存在单点问题\nGFS: 文件存储,大文件,数据拆分\nFastDFS : fast distribute file system, 小文件 ,数据不拆分\n"},{"id":21,"href":"/docs/%E5%85%B6%E4%BB%96/%E7%96%91%E9%9A%BE%E6%9D%82%E7%97%87/","title":"疑难杂症","section":"其他","content":" 华盛通2023-07-07 一面 # spring中的设计模式 # Aop机制 # 面向切面变成, 基于jdk 动态代理和cglib动态代理实现, 可以为方法指定对应的切面 ,从而动态扩展方法功能 , 比如为远程方法调用增加日志、trace.等\njdk动态代理:运行时动态代理技术, 可以实现对接口的动态代理, 实现对象的invoactionhandler 来扩展原有类中方法的功能, 底层使用代理模式,重新生成一个代理类, 在调用方法之前或者之后 加载invocationhandler里面的扩展方法,只能对方法进行动态代理,\ncglib: 编译时字节码增强技术, 可以对字段、类、方法进行字节码增强\nspring -aop: 对jdk动态代理、cglib进行包装, 常用的注解, @Aspect 定义切面 , @PointCut 定义切人点 ,切入点即拦截的方法位置 , @Around 、@Before @After 定义Advice 通知, 比如加日志、监控、上报指标等\nkafka消息积压如何处理, 加消费者后rebalance如何解决分区重分配问题 # rebalance 无法避免\nredis节点挂掉如何处理 # ping消息获取节点信息:\n投票过程是集群中所有master参与,如果半数以上master节点与master节点通信超时(cluster-node-timeout),认为当前master节点挂掉。\n如果无对应的salve节点, 集群直接不可用\nslave 节点发小master节点挂掉后,开始raft 选举, offset 最大的节点优先选举, offset比较小的延迟选举\n扩展信息\nkafka ​\tleader follower 挂掉后也是类似的原则, 由controller节点 , 从AR 副本 (ISR) 中选取一个副本作为leader 副本\nelasticesarch (bully算法) master节点选举: activeMaster列表是其它节点认为的当前集群的Master节点列表，如果activeMasters列表不为空，elasticsearch会优先从activeMasters列表中选举，也就是对应着流程图中的蓝色框，选举的算法是Bully算法，笔者在前文中详细介绍了Bully算法，Bully算法会涉及到优先级比较， 在activeMasters列表优先级比较的时候，如果节点有成为master的资格，那么优先级比较高，如果activeMaster列表有多个节点具有master资格，那么选择id最小的节点\n线程池 # 线程数量如何规划\ncpu类型的 N+1, IO密集型2N\narraylist 、linklist插入数据时间复杂度、空间复杂度 # clickhouse物化视图实现,是否存在一致性问题 # elasticsearch # 主分片 # ​\t主节点负责创建索引、删除索引、分配分片、追踪集群中的节点状态等工作, bully 、raft算法选取主节点\nmaster节点选举 # ​\t从候选节点中选择 id 最小的节点作为主节点, bully算法\n分片分配 # ​\tmaster 节点进行分片数据分配. 通过将in-sync列表的分片遍历各个decider，如果有任一deny发生，则拒绝本次分配。决策结束之后可能会有多个节点，取第一个节点上的分片作为主分片。 (类似kafka 副本故障转移技术)\njava算法 常用函数 # list删除元素 # arrays.remove();\nint[] 数组转化尽量用arraylist # 二叉搜索树与双向链表:https://www.nowcoder.com/practice/947f6eb80d944a84850b0538bf0ec3a5?tpId=295\u0026amp;tqId=23253\u0026amp;ru=/exam/oj\u0026amp;qru=/ta/format-top101/question-ranking\u0026amp;sourceUrl=%2Fexam%2Foj # 是否是二叉搜索树 # Array.copyOf({原数组},数组长度);\n2023-07-10 乐信集团- 一面 # elasticsearch 数据删除之后会发生什么 # 标记删除,还是会存在对应的数据, es内部维护线程进行段的合并。删除后可能导致性能不降反升, 可以调用es的merge 接口手动进行的段合并\n是否会存在大合并 # es 数据查询变慢问题排查 : # 删除数据,导致cpu飙升, 可以手动进行es段的合并\n2023-07-11 国泰产险-一面 # 压测如何进行\njmeter 还是自定义、\n2023-07-11 华盛通 二面 # 2023-07-12 健康160一面 # ribbon负载均衡 # 限流 # ​\tsentinel限流\n​\tGuava Rate limit :基于令牌桶算法\n本地限流: 每个节点分配一定的流量, 查询是判断是否流量是否控制范围内,若是, 正常执行, 否的话,拒绝, 每隔一段时间拉取对应的流量,\n分布式限流: 针对并发比较小的情况\nTCC事务机制 ,事务悬挂问题 # tcc 三个阶段:\ntry\nconfirm\ncancel\n需要业务保证,幂等性、空回滚、事务悬挂问题\n事务悬挂: 先try 、后cancel , try 后到达, 导致先进行了cancel ,try 资源被悬挂,解决方案 ,执行try的时候需要判断下是否先执行了cancel ,如果执行不用执行try了\n范型 # 优势\n类型安全,可以在编译期进行类型擦出,及时发现类型安全问题 使用范型,可以编写更加通用的代码,提高代码的灵活性 使用时,可以避免频繁类型转换 局限性:\n无法使用基本类型作为类型参数，例如List是不允许的，需要使用包装类List代替。 无法创建具有泛型类型参数的数组，例如new T[]是不合法的，可以使用List代替。 elasticsearch 有多少种查询方式 # term查询（精准查询） math查询（分词匹配查询） fuzzy查询（模糊查询） wildcard(通配符查询) bool查询（布尔查询） 分页查询\nfrom + size,分页限制1万,超过会报错 search after 利用实时有游标来帮我们解决实时滚动的问题。第一次搜索时需要指定 sort，并且保证值是唯一的，可以通过加入 _id 保证唯一性。缺点: 可以实时高效的进行分页查询，但是它只能做下一页这样的查询场景，不能随机的指定页数查询 scroll api 创建一个快照，有新的数据写入以后,无法被查到。每次查询后，输入上一次的 scroll_id。目前官方已经不推荐使用这个API了，使用search_after即可。 redis list用途 # redis 重启如何恢复数据 (rdb、aof) # ​\t如果同时使用RDB和AOF两种持久化机制，那么在redis重启的时候，会使用AOF来重新构建数据，因为AOF中的数据更加完整\nredis 使用注意事项 # kafka如何保证幂等性 # 创建线程的方式 # 继承thread 实现runnable接口 实现callable接口 , new FutrueTask({Callable接口实现}) 通过线程池 2023-07-13 盛业一面 # 500万数据多个数据组合查询,如何进行优化\n大表数据字段变更\n分布式锁 , 数据库实现分布式锁, 节点挂掉后, 锁会被释放掉吗?\n2023-07-13 华润 # http 常见请求头\n跨域问题\nsha256\nfinal方法\nfeign 注解 # ​\t@FeignClient @RequestMapping\ndocker compose 最佳实践\n注册中心设计:\n2023-07-13 after-ship (一面挂) # 场景类设计题目、堆 问题 , 感觉都答的差不多, 面试官说可以过, 最终挂了, 不知道啥原因\n2023-07-14 华盛hr面 # 2023-07-17 shein - 一面(挂) 30分钟左右 # young gc -如何进行垃圾回收 ,频繁youngc 会有什么问题 # younggc 采用复制算法, 频繁younggc cpu 会飙升\nkafka 消息堆积 ,如何解决 # 调整消费者拉取数据量大小\n调整提交时间间隔\n消息异步化处理(提升消费速度,避免积压)\nreetranlock 、synchronized 除了实现方式还有甚么区别 # 锁区别, 公平锁、 非公平锁\n是否可中断 , 不可中断、可中断\n手动加锁、释放 ,reentrantlock 需要在finally 里面手动释放锁, 否则会导致锁一致得不到释\ncondition 、wait 、notifyALL 区别\n主动缓存里面的key是什么 # 接口 + 请求参数\n大key存储问题 # 线程池停止的方式 # shutdown shutdownnow awaitTermination, 请求等待一段时间后 redis 集群模式如何感知节点变化 # lecture 开起定时更新网络结构配置 和 感知节点故障后 惰性更新配置 , 更新集群对应的不可用刷新间隔 redission 可以自动感知集群拓扑变化 2023-07-17 唯品会一面 (1个小时) # redis 集群如何实现mget # 二级缓存如何实现 # springcache 、caffine 、\n利用redis的发布订阅模式更新本地缓存数据\ncaffeine-redis-sping-boot-starter\n订阅db里面的数据,同步更新redis缓存, redis 中利用pub/sub机制更新本地缓存\n什么时候需要自定义类加载器 # tomcat 自定义类加载器, 可以隔离web服务下不同jar之间的版本, 每个web容器只加载相应版本的jar\n2023-07-18 乐信二面(30分钟) # 数据库为什么推荐用自增id作为主键索引 # 如果主键为自增 id 的话，mysql 在写满一个数据页的时候，直接申请另一个新数据页接着写就可以了。 如果主键是非自增 id，为了确保索引有序，mysql 就需要将每次插入的数据都放到合适的位置上。 身份证号码如何做索引、频繁更新 # 识别身份证号的关键信息 、 hash取值后做索引、 冗余一个字段做更新\nepoll 边缘触发和水平触发 # zset linklist 如何保证性能不退化成链表, 有个随机数,插入节点的时候按照概率, 越少层概率越小. 使得层数尽可能的均匀\ninnodb的四大特性 # 插入缓存 二次写 自适应哈希 预读 2023-07-18 健康160二面 # 项目问题一个个问\n如何确保微信id数据问题\n2023-07-19 -盛业二面 (30分钟 ,估计没戏-最后过了) # 2023-07-19 华润二面(1个小时) # 如何保证分布式事务的一致性,设计一种通用方案 ,最终消息一致性\nhttp各版本区别 , 最新到http3.0 web3.0, 基于udp\n2023-07-20 富图一面 # 四次挥手过程 # 最有有个timewait的过程,防止ack失败的情况出现\ndns污染 # dns劫持 # dns泄漏 # dns 解析过程 : # 主机先向本地域名服务器进行递归查询 本地域名服务器采用迭代查询，向一个根域名服务器进行查询 根域名服务器告诉本地域名服务器，下一次应该查询的顶级域名服务器的IP地址 本地域名服务器向顶级域名服务器进行查询 顶级域名服务器告诉本地域名服务器，下一步查询权限服务器的IP地址 本地域名服务器向权限服务器进行查询 权限服务器告诉本地域名服务器所查询的主机的IP地址 本地域名服务器最后把查询结果告诉主机 backlog:全链接队列 , somaxconnection # 即全连接队列长度 = min(backlog, 内核参数 net.core.somaxconn)\n队列满了容易出现丢包的情况发生\n增大 TCP 半连接队列和全连接队列的方式 # 增大 TCP 半连接队列的方式是增大 /proc/sys/net/ipv4/tcp_max_syn_backlog； 增大 TCP 全连接队列的方式是增大 listen() 函数中的 backlog； ss命令 可以查看全连接队列\n如何防止syn攻击\n增大半连接队列； 开启 tcp_syncookies 功能 减少 SYN+ACK 重传次数 502 错误排查 # 服务器作为网关, 请求上游得不到正常的返回\n2023-07-21 -健康160三面(40分钟左右) # 职业生涯规划, 整体状态不太好, 没有说明自己的远期规划是什么,后面需要特别准备下 , 尤其是ai 相关领域,\n2023-07-21 - 阿里lazada (一面-1个小时) # 一道算法题, 求完全二叉树的最后一个节点 , 面试官比较nice ,体验很好 ,没怎么问八股文\n简单问了下threadlocal\njava、 go 之间的不同\n完全二叉树的最后一个节点.\n2023-07-24 唯品会二面(45分钟-挂) # 索引的实现原理 # MyISAM,非聚簇索引\ninnodb 聚簇索引,底层B+树\n2023-07-23 阿里lazada 二面(一个小时\u0026ndash; 要挂,面试官不按常理出牌-最后过了) # 数据库 groupby 如何进行优化 # 原始groupby过程\n临时表(内存或者磁盘) , 走索引,本身自带去重操作,就不会使用临时表了 orderby 排序,filesort(内存,磁盘) 优化\nelasticsearch 有过哪些优化\n查询优化 插入优化 硬件配置优化 数据字段优化, 合理设计分词,合理使用缓存 服务端合理设置分片,refresh(默认1秒)、tranlog时间(默认5秒) 2023-07-25 - 富图 # 系统调用是什么 # 证书如何签名、如何保证安全 # ca机构办法证书会对证书信息进行签名, 签名后有私钥进行加密, 浏览器内置了主流ca的公钥,可以揭秘对应的签名,采用相同的签名算法看两次签名是否一致即可\nBIO、NIO区别, 同步与异步的区别 # 如何避免死锁问题 # 2023-07-25 - oppo 一面数据平台开发 # 没咋准备 ,估计凉了 , 凉就凉吧 ,无所谓了\nmaven的几种依赖scope , compile 、test、runtime\nspark 任务\njedis 常用的配置\nast解析\njoin优化\nclickhouse 常用的引擎\nclickhouse 建表语句,skiplist\n2023-07-26 富图三面(35分钟左右概率题没有分析出来,要凉最后过了) # 概率题: 硬币空杯子概率,交换,因为交换之后的概率是2/3\n中文词检索: trie树\ngo cpu调度\ngo 内存分配机制\nclose-wait 如何处理\n进程挂掉后 os层面的连接会如何处理\n2023-07-26 小红书(一面1小时25分钟) # 直接来个算法设计题(不怎么会,设计完我还是蒙圈的)\ninterface SmartCache { String get(String key); } //不考虑set操作\n1.如果key不为热点，则从DB获取 return getFromDB(key); // getFromDB()无需代码实现\n2.如果key为热点，则将DB数据缓存到本地的某个数据结构，优先从本地缓存读取\n定义最近N秒内访问次数超过M的key为热点key（M和N是固定的常数）\n消息写入redis , 如何避免热key问题 # 客户端规定时间批量写入\n写入时给个随机数\nmq 错峰写入(会有延迟)\n2023-07-27 阿里lazada 三面 # 入账出账是什么意思\n平台类型账号转账如何提高并发和实时性\n2023-07-28 - oppo二面(画像) # 2023-07-28 - 中国移动 # 围着项目问\n2023-07-30 沃尔玛(一二面) # 场景设计题 ,现有模型 ,然后根据模型进行对应的技术选型 ,\n考虑一些常见的问题 ,例如流量、安全 等\n2023-07-31 小红书二面(应该是凉了-过) # 给了一个算法 , 移动非0元素到最左侧 , 出了个乌龙,交换元素没搞对\n2023-08-01 无觅-二面 # 资源有限的情况下,如何提升资源利用率\n2023-08-01 oppo-三面 # 没问问题\n2023-08-01- 字节一面 # redis 热key问题\n2023-08-02 平安一面 # 项目面试\n设计\n交替打印问题\n有哪些还没有被发掘的点\n2023-08-03 shopee一面 # 实现单链表的快速排序\n2023-08-08 荣耀三面四面 # DDD领域设计模式\n按照领域进行设计,尽可能少的减少业务影响对代码的干扰\n战术设计: 边界上下文、核心子域、通用子域、支撑子域,实体、值对象\n领域事件\n战术设计: 用户接口层、应用层、领域层、接口层\n洋葱模型、六边形架构(各种防腐层、VO、DTO、DO转换)\n2023-08-09 小红书三面 # 架构变更hc调整, 到三面 没有后续了, 估计招到人了 ,不推进后续流程了\n2023-08-09 字节(45分钟) # 数组最大容量\n推荐算法,如何保证推荐不重复\n2023-08-14 -字节三面 # 项目qps 、tps 之类的,需要考虑面试者对项目的熟悉程度 # 设计一个停车场收费系统 # "},{"id":22,"href":"/docs/%E5%85%B6%E4%BB%96/%E7%AE%97%E6%B3%95/","title":"算法","section":"其他","content":"1、list\nreturn arr.stream().mapToInt(Integer::valueOf).toArray();\nfor(Map.Entry\u0026lt;Integer,Integer\u0026gt; ks : m.entrySet()){\n​ if(ks.getValue()==maxV){\n​ arr.add(ks.getKey());\n​ }\n​ }\nNew String(char[], start, size)\nint ret = (int)(Math.pow(2,h)) -1; 求2的h次方\n"},{"id":23,"href":"/docs/%E5%88%86%E5%B8%83%E5%BC%8F/gossip%E5%8D%8F%E8%AE%AE/","title":"Gossip协议","section":"分布式","content":"NoSQL 数据库 Redis 和 Apache Cassandra、服务网格解决方案 Consul 等知名项目都用到了 Gossip 协议，学习 Gossip 协议有助于我们搞清很多技术的底层原理。\n我们这里以 Redis Cluster 为例说明 Gossip 协议的实际应用。\n我们经常使用的分布式缓存 Redis 的官方集群解决方案（3.0 版本引入） Redis Cluster 就是基于 Gossip 协议来实现集群中各个节点数据的最终一致性。\n有了 Redis Cluster 之后，不需要专门部署 Sentinel 集群服务了。Redis Cluster 相当于是内置了 Sentinel 机制，Redis Cluster 内部的各个 Redis 节点通过 Gossip 协议互相探测健康状态，在故障时可以自动切换。\n著作权归Guide所有 原文链接：https://javaguide.cn/distributed-system/protocol/gossip-protocl.html#gossip-%E5%8D%8F%E8%AE%AE%E4%BB%8B%E7%BB%8D\n"},{"id":24,"href":"/docs/%E5%88%86%E5%B8%83%E5%BC%8F/paxos/","title":"Paxos","section":"分布式","content":"Basic Paxos 中存在 3 个重要的角色：\n提议者（Proposer）：也可以叫做协调者（coordinator），提议者负责接受客户端的请求并发起提案。提案信息通常包括提案编号 (Proposal ID) 和提议的值 (Value)。 接受者（Acceptor）：也可以叫做投票员（voter），负责对提议者的提案进行投票，同时需要记住自己的投票历史； 学习者（Learner）：如果有超过半数接受者就某个提议达成了共识，那么学习者就需要接受这个提议，并就该提议作出运算，然后将运算结果返回给客户端。 为了减少实现该算法所需的节点数，一个节点可以身兼多个角色。并且，一个提案被选定需要被半数以上的 Acceptor 接受。这样的话，Basic Paxos 算法还具备容错性，在少于一半的节点出现故障时，集群仍能正常工作。\nPaxos 三种角色:Proposer，Acceptor，Learners # Proposer:\n只要 Proposer 发的提案被半数以上 Acceptor 接受，Proposer 就认为该提案里的 value 被选定 了。\nAcceptor: 只要 Acceptor 接受了某个提案，Acceptor 就认为该提案里的 value 被选定了。\nLearner: Acceptor 告诉 Learner 哪个 value 被选定，Learner 就认为那个 value 被选定。\n著作权归Guide所有 原文链接：https://javaguide.cn/distributed-system/protocol/paxos-algorithm.html#%E4%BB%8B%E7%BB%8D\n"},{"id":25,"href":"/docs/%E5%88%86%E5%B8%83%E5%BC%8F/zab%E5%8D%8F%E8%AE%AE/","title":"Zab协议","section":"分布式","content":" ZAB( ZooKeeper Atomic Broadcast , ZooKeeper 原子消息广播协议)协议包括两种基本的模 式:崩溃恢复和消息广播 # **1.**崩溃恢复:主要就是 Leader 选举过程\n2.**数据同步:Leader 服务器与其他服务器进行数据同步\n**3.**消息广播:Leader 服务器将数据发送给其他服务器\n"},{"id":26,"href":"/docs/%E5%88%86%E5%B8%83%E5%BC%8F/%E4%BA%8B%E5%8A%A1/","title":"事务","section":"分布式","content":" TCC事务 # try\nconfirm\ncancel\nXA # RM\nTM\nAP\n两阶段提交 # 三阶段提交 # 本地消息表 # 最大努力通知 # SAGA # AT(SEATA) # "},{"id":27,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhosue/sql-join/","title":"SQL Join","section":"clickhosue","content":"clickhouse\n常用操作\njoin # 所有的join 操作基本范式都是\n​\ttable1 join table2 on table.xxx=table2.xxx\n​\tjoin table3 on table1.xxx=table3.xxx\n​\tjoin table4 on table2.xxx=table4.xxx\n不允许先查询 再进行join,错误查询示例\nselect * from table_a where age=12 (inner) join table_b on table_a.id =table_b.id left joni table_c on table a.id=table_c.id where table_a.name=\u0026#39;xxxx\u0026#34; (inner)join操作 # ​\t内连接,去两个表on 交集\nselect * from table_a (inner) join table_b on table_a.id =table_b.id where table_a.name=\u0026#39;\u0026#39;xxxx\u0026#34; ​\nLeft join # 左边为空时,会导致不会查到任何数据\n左连接,取左表所有\nselect * from table_a left join table_b on table_a.id =table_b.id where table_a.name=\u0026#39;\u0026#39;xxxx\u0026#34; right join # 右表所有,加on条件左表\nselect * from table_a right join table_b on table_a.id =table_b.id where table_a.name=\u0026#39;\u0026#39;xxxx\u0026#34; full join\nself join\ncross join\nunion all /union distinct # 基本语法\nSELECT column1, column2 ... FROM table1, table2 [WHERE condition1] UNION / UNION ALL SELECT column1, column2 ... FROM table1, table2 [WHERE condition2] union distinct会对数据进行去重,(mysql中union 本身就具有去重逻辑) union all 直接将结果数据进行连接 "},{"id":28,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhosue/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/","title":"物化视图","section":"clickhosue","content":"物化视图相关功能\n"},{"id":29,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/clickhosue/%E8%BF%90%E7%BB%B4%E7%9B%B8%E5%85%B3/","title":"运维相关","section":"clickhosue","content":" system.clusters表 # 作用: 查询系统的集群信息\nsystem.query_log # 系统日志:\nsystem.parts # 系统表:根据此表可以查询表的分区信息,以及占用的空间大小\nSELECT TABLE, -- 表名 DATABASE, -- 数据库名 max(partition) AS part, -- 最大分区 formatReadableSize(sum(bytes_on_disk)) AS SIZE, -- 磁盘容量 sum(bytes_on_disk) AS size_bytes -- 磁盘容量 FROM system.parts_all GROUP BY TABLE, DATABASE ORDER BY size_bytes DESC system.disks # 查询磁盘使用率\nSELECT sum(total_space -free_space)/sum(total_space) AS USAGE, -- 使用率 count(*) , -- 节点数量 formatReadableSize(sum(total_space -free_space)) AS foramat_usage, -- 使用空间大小 formatReadableSize(sum(total_space)) AS format_total --总空间大小 FROM clusterAllReplicas(\u0026#39;clickhouse_pcg_video_data_science_2_replica\u0026#39;,system,disks); 数据导出命令 # mysql -h{host} -u{user}-P{port} -D{db} --password=\u0026#39;{passwod}\u0026#39; -e \u0026#34;sql\u0026#34; \u0026gt; file.csv "},{"id":30,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch/%E6%95%B0%E6%8D%AE%E5%88%86%E7%89%87/","title":"数据分片","section":"elasticsearch","content":"TODO\n"},{"id":31,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/elasticsearch/%E8%B0%83%E4%BC%98/","title":"调优","section":"elasticsearch","content":"TODO\n"},{"id":32,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/mvcc%E6%A8%A1%E5%9E%8B/","title":"Mvcc模型","section":"mysql","content":"TODO\n"},{"id":33,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E4%BA%8B%E5%8A%A1/","title":"事务","section":"mysql","content":"TODO\n"},{"id":34,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%94%81/","title":"锁","section":"mysql","content":" 概览 # 全局锁 # 示例:\nflush tables with read lock --加锁 unlock tables --解锁 用途: 全库备份,期间不允许数据修改\n表级别锁 # 1.表锁 # lock tables t_student read; --表级别的共享锁，也就是读锁； unlock tables --解锁 lock tables t_stuent write; -- 表级别的独占锁，也就是写锁； unlock tables --解锁 2.元数据锁 # 再来说说元数据锁（MDL）。\n我们不需要显示的使用 MDL，因为当我们对数据库表进行操作时，会自动给这个表加上 MDL：\n对一张表进行 CRUD 操作时，加的是 MDL 读锁； 对一张表做结构变更操作的时候，加的是 MDL 写锁； MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。\n当有线程在执行 select 语句（ 加 MDL 读锁）的期间，如果有其他线程要更改该表的结构（ 申请 MDL 写锁），那么将会被阻塞，直到执行完 select 语句（ 释放 MDL 读锁）。\n反之，当有线程对表结构进行变更（ 加 MDL 写锁）的期间，如果有其他线程执行了 CRUD 操作（ 申请 MDL 读锁），那么就会被阻塞，直到表结构变更完成（ 释放 MDL 写锁）。\nMDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的。\n3.意向锁 # 也就是，当执行插入、更新、删除操作，需要先对表加上「意向独占锁」，然后对该记录加独占锁。而普通的 select 是不会加行级锁的，普通的 select 语句是利用 MVCC 实现一致性读，是无锁的。\n意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和共享表锁（*lock tables \u0026hellip; read*）和独占表锁（*lock tables \u0026hellip; write*）发生冲突。\n意向锁的目的是为了快速判断表里是否有记录被加锁。\n4.AUTO-INC 锁 # 里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。\n之后可以在插入数据时，可以不指定主键的值，数据库会自动给主键赋值递增的值，这主要是通过 AUTO-INC 锁实现的。\nAUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。\n在插入数据时，会加一个表级别的 AUTO-INC 锁，然后为被 AUTO_INCREMENT 修饰的字段赋值递增的值，等插入语句执行完成后，才会把 AUTO-INC 锁释放掉。\n那么，一个事务在持有 AUTO-INC 锁的过程中，其他事务的如果要向该表插入语句都会被阻塞，从而保证插入数据时，被 AUTO_INCREMENT 修饰的字段的值是连续递增的。\n但是， AUTO-INC 锁再对大量数据进行插入的时候，会影响插入性能，因为另一个事务中的插入会被阻塞。\n行级锁 # 记录锁record lock # 间隙锁gap lock # next-key lock # 插入意向锁 # 一个事务在插入一条记录的时候，需要判断插入位置是否已被其他事务加了间隙锁（next-key lock 也包含间隙锁）。如果有的话，插入操作就会发生阻塞，直到拥有间隙锁的那个事务提交为止（释放间隙锁的时刻），在此期间会生成一个插入意向锁，表明有事务想在某个区间插入新记录，但是现在处于等待状态。\n"},{"id":35,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","title":"分布式锁","section":"redis","content":"http://kaito-kidd.com/2021/06/08/is-redis-distributed-lock-really-safe/\nredission 实现分布式锁 , 不能解决主从切换问题,\nredlock 解决主从切换问题\n"},{"id":36,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E5%8F%8C%E5%86%99%E4%B8%80%E8%87%B4%E6%80%A7/","title":"双写一致性","section":"redis","content":"redis与 db双写一致性问题\n先更新redis,后更新数据库 # 先更新数据库,后更新redis # 先删除redis,后更新数据库 # 先更新数据库,后删除redis # "},{"id":37,"href":"/docs/%E6%95%B0%E6%8D%AE%E5%BA%93/redis/%E6%9E%B6%E6%9E%84/","title":"架构","section":"redis","content":" redis 架构 # 持久化方式 # rdb: fork进程\naof: 一个线程,\nredis基础数据结构\nstring类型:SDS ,简单字符串, 获取字符串容量 需要时间o(1), 是安全的,不会造成缓存区溢出\n详细: https://www.cnblogs.com/xiaolincoding/p/15628854.html\n一致性hash: # 一致哈希 是一种特殊的哈希算法。在使用一致哈希算法后，哈希表槽位数（大小）的改变平均只需要对 K/n 个关键字重新映射，其中 K 是关键字的数量，n 是槽位数量。然而在传统的哈希表中，添加或删除一个槽位的几乎需要对所有关键字进行重新映射。\n多级缓存: # 缓存更新、缓存一致性问题\n主从复制原理 # 当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件。 同时还会将从客户端 client 新收到的所有写命令缓存在内存中。RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中。 接着 master 会将内存中缓存的写命令发送到 slave，slave 也会同步这些数据。 slave node 如果跟 master node 有网络故障，断开了连接，会自动重连，连接之后 master node 仅会复制给 slave 部分缺少的数据。\n线上redis集群配置? (可选项) # redis-cluster集群特性 # 无法使用0 号数据库\nredis分区(分片) # 客户端路由\nproxy代理路有\n查询路由\n缺点: 不支持多个key,不能进行管道操作,不能使用redis事务,不能对集合求交集\n集群扩容,扩容分区 # 缓存的几个注意事项 # 缓存雪崩\n缓存穿透 : 数据都没有, 采用bloom-filter 过滤器, 多个hash函数\n缓存击穿\n缓存预热\n缓存降级\n热点key缓存问题(加锁):\n​\t对缓存查询加锁，如果 KEY 不存在，就加锁，然后查 DB 入缓存，然后解锁；其他进程如果发现有锁就等待，然后等解锁后返回数据或者进入 DB 查询\n缓存一执性问题 # 主从一致性问题 # scan命令(游标查询) # 假如 Redis 里面有 1 亿个 key，其中有 10w 个 key 是以某个固定的已知的前缀开头的，如果将它们全部找出来？\n使用 keys 指令可以扫出指定模式的 key 列表。\n对方接着追问：如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？\n这个时候你要回答 redis 关键的一个特性：redis 的单线程的。keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。\nredis实现分布式锁\nredis 数据接口\nSDS:简单字符串,\nSet:\nHash:\nredis优化 # 1、尽量不要使用慢查询语句\n2、 大key\n3、不要使用keys 语句, 改为scan\n4、 合理的数据结构, 比如redis 会对hash存储做压缩优化, 直接存储key 会导致数据占用更大的存储空间, 而hash 则可以利用redis内容的优化手段降低内存使用率\n5、 尽量关闭swap ,性能很差\n6、 使用pipline 来优化查询, 在集群模式下不生效\n7、开启内存碎片清理 ,自动内存碎片\n8、合理设置backlog的大小，应设置成在服务端最大能够承受qps的1-1.5倍左右。\nredis 分布式锁\n时间轮机制 # 定时任务轮训 ,可以考虑使用这个数据结构\n时间轮机制是一种高效的定时任务调度算法，通过使用循环数组和时间槽的方式，实现了简单、可扩展和高效的定时任务管理。\nkafka 知识点 # 读数据 # 根据稀疏索引，快速定位到要消费的数据 零拷贝机制 减少数据的拷贝 减少了应用程序与操作系统上下文切换 ![image-20230704110442310](/Users/wuguangkuo/Library/Application Support/typora-user-images/image-20230704110442310.png)\n高可用 # 在kafka里面分区是有副本的，注：0.8以前是没有副本机制的。创建主题时，可以指定分区，也可以指定副本个数。副本是有角色的：leader partition：1、写数据、读数据操作都是从leader partition去操作的。2、会维护一个ISR（in-sync- replica ）列表，但是会根据一定的规则删除ISR列表里面的值 生产者发送来一个消息，消息首先要写入到leader partition中 写完了以后，还要把消息写入到ISR列表里面的其它分区，写完后才算这个消息提交 follower partition：从leader partition同步数据。\n写数据 # 把数据先写入到OS Cache 写到磁盘上面是顺序写，性能很高 数据过期 # 按照日志时间进行过期 按照容量 网络架构 # 规划 # 一般情况下，我们评估机器的时候，是按照高峰期的4倍的去评估,遵循28原则\n物理机 or 虚拟机 磁盘 ,SSD固态硬盘，还是需要普通的机械硬盘**SSD硬盘：性能比较好，但是价格贵 SAS盘：某方面性能不是很好，但是比较便宜。SSD硬盘性能比较好，指的是它随机读写的性能比较好。适合MySQL这样集群。**但是其实他的顺序写的性能跟SAS盘差不多。kafka的理解：就是用的顺序写。所以我们就用普通的【机械硬盘】就可以了。 原文章链接 https://mp.weixin.qq.com/s/V1KSIrIURCsrX7fCmq2NtQ # https 执行过程 # java基础 # 锁:\n偏向锁 、 轻量级锁、重量级锁 、 自旋锁、\nGO面试 # GMP 模型 # key\u0026mdash;key\u0026mdash;\u0026gt;value形式 还是key-value形式\nleecode 常用函数:\nsort.Slice\nsort.Ints\n"},{"id":38,"href":"/docs/%E6%9E%B6%E6%9E%84/","title":"架构","section":"Docs","content":"负载均衡介入层\n应用集群层\n分布式服务层\n资源层\nqps\nredis 单机 10万qps\n单个应用\n数据库8C 16G, 几千qps 左右\n单机数据库 \u0026mdash;\u0026ndash;\u0026gt; 分业务\u0026mdash;\u0026mdash;\u0026mdash;-\u0026gt; 读写分离\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\u0026gt; 分库分表\nclickhouse 写入50万 qps\nkakfa 使用Kafka 使用到了 mmap 和 sendfile 的方式来实现零拷贝。分别对应 Java 的 MappedByteBuffer 和 FileChannel.transferTo\n"},{"id":39,"href":"/docs/%E6%9E%B6%E6%9E%84/%E5%BE%AE%E4%BF%A1%E6%9E%B6%E6%9E%84/","title":"微信架构","section":"架构","content":"微信架构\nadfasdf\ndfsasdfads\n"},{"id":40,"href":"/docs/%E7%AE%97%E6%B3%95/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","title":"动态规划","section":"算法","content":"TODO\n"},{"id":41,"href":"/docs/%E7%AE%97%E6%B3%95/%E5%9B%9E%E6%BA%AF/","title":"回溯","section":"算法","content":"TODO\n设计思路\n全局变量： 保存结果 参数设计： 递归函数的参数，是将上一次操作的合法状态当作下一次操作的初始位置。这里的参数，我理解为两种参数：状态变量和条件变量。（1）状态变量（state）就是最后结果（result）要保存的值；（2）条件变量就是决定搜索是否完毕或者合法的值。 完成条件： 完成条件是决定 状态变量和条件变量 在取什么值时可以判定整个搜索流程结束。搜索流程结束有两种含义： 搜索成功并保存结果 和 搜索失败并返回上一次状态。 递归过程： 传递当前状态给下一次递归进行搜索。 void backtrace(初始数据,中间数据存储, 结果数据 )\n结果数据要定义好 初始数据要根据需要取单个值或者原始数组 数组全排列:\nhttps://leetcode.cn/problems/permutations/solution/ newArr:=make([]int,len(arr))\ncopy(newArr,arr) copy的时候需要指定length和cap\nleecode 题目 https://leetcode.cn/problems/combinations/submissions/\nfunc Combine(n int, k int) [][]int { var ret = make([][]int, 0) var backTrace func(start int, num int, retArr *[][]int, temp []int) backTrace = func(start int, num int, retArr *[][]int, temp []int) { if len(temp) == k { *retArr = append(*retArr, temp) return } if start \u0026gt; n { return } //chose i copyTemp := make([]int, len(temp)) copy(copyTemp, temp) temp = append(temp, start) if start == 4 { fmt.Println(start) } backTrace(start+1, num-1, retArr, temp) // not chose i backTrace(start+1, num, retArr, copyTemp) // 从第一次选择和不选择的情况,已经确定了后面的所有情况 } //for i := 1; i \u0026lt;= n; i++ { backTrace(1, k, \u0026amp;ret, nil) //这里注意不要用外层for //} return ret } "},{"id":42,"href":"/docs/%E7%AE%97%E6%B3%95/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/","title":"贪心算法","section":"算法","content":"贪心算法定义\n"},{"id":43,"href":"/menu/","title":"Index","section":"Introduction","content":" headless: true # "}]